"""
Final Clean Comparison: Enhanced vs Static LeViT
===============================================

Clean comparison using the same training methodology for both models.
"""

import torch
import torch.nn as nn
import torch.optim as optim
import time
import os
import numpy as np
import psutil
import platform
from enhanced_levit_training import load_datasets, evaluate_enhanced_levit
from enhanced_adaptive_levit import create_enhanced_levit, create_fast_enhanced_levit
import levit

class PowerMonitor:
    """Monitor power consumption during inference"""
    def __init__(self, device):
        self.device = device
        self.gpu_available = torch.cuda.is_available()
        self.measurements = []
        self.gpu_energy_supported = False
        self.gpu_handle = None
        
    def start_measurement(self):
        """Start power measurement"""
        if self.gpu_available:
            torch.cuda.synchronize()
            # GPU power monitoring (if nvidia-ml-py available)
            try:
                import pynvml
                pynvml.nvmlInit()
                self.gpu_handle = pynvml.nvmlDeviceGetHandleByIndex(0)
                # Prefer energy counter if supported (milli-Joules)
                try:
                    self.gpu_energy_supported = True
                    self.gpu_energy_start_mj = pynvml.nvmlDeviceGetTotalEnergyConsumption(self.gpu_handle)
                except Exception:
                    self.gpu_energy_supported = False
                    self.gpu_power_start = pynvml.nvmlDeviceGetPowerUsage(self.gpu_handle) / 1000.0  # Watts
            except:
                self.gpu_power_start = None
        
        # CPU power estimation
        self.cpu_percent_start = psutil.cpu_percent(interval=None)
        self.start_time = time.time()
        
    def end_measurement(self):
        """End power measurement and return average power"""
        if self.gpu_available:
            torch.cuda.synchronize()
            try:
                import pynvml
                if self.gpu_energy_supported:
                    energy_end_mj = pynvml.nvmlDeviceGetTotalEnergyConsumption(self.gpu_handle)
                    gpu_energy_j = max(0.0, (energy_end_mj - getattr(self, 'gpu_energy_start_mj', energy_end_mj)) / 1000.0)
                    # Average GPU power from energy over duration (computed below)
                    gpu_power_avg = None
                else:
                    gpu_power_end = pynvml.nvmlDeviceGetPowerUsage(self.gpu_handle) / 1000.0
                    gpu_power_avg = (self.gpu_power_start + gpu_power_end) / 2.0 if self.gpu_power_start else 0
            except:
                gpu_power_avg = 0
        else:
            gpu_power_avg = 0
            
        # CPU power estimation (rough approximation)
        cpu_percent_end = psutil.cpu_percent(interval=None)
        cpu_percent_avg = (self.cpu_percent_start + cpu_percent_end) / 2.0
        
        # Estimate CPU power consumption (very rough approximation)
        # Modern CPUs: ~15W idle + ~(cpu_percent/100) * 50W under load
        cpu_power_avg = 15 + (cpu_percent_avg / 100.0) * 50
        
        end_time = time.time()
        duration = end_time - self.start_time
        # If we have GPU energy, compute avg GPU power from it; else approximate
        if self.gpu_available:
            try:
                import pynvml
                if self.gpu_energy_supported:
                    gpu_power_avg = gpu_energy_j / max(1e-9, duration)
                    gpu_energy = gpu_energy_j
                else:
                    gpu_energy = gpu_power_avg * duration
            except:
                gpu_energy = gpu_power_avg * duration
        else:
            gpu_energy = 0.0

        total_power = (gpu_power_avg or 0.0) + cpu_power_avg
        energy = gpu_energy + cpu_power_avg * duration  # Joules
        
        return {
            'duration': duration,
            'gpu_power_w': gpu_power_avg if gpu_power_avg is not None else (gpu_energy / max(1e-9, duration)),
            'cpu_power_w': cpu_power_avg, 
            'total_power_w': total_power,
            'energy_j': energy,
            'energy_wh': energy / 3600.0  # Convert to Watt-hours
        }

def train_static_model(model_name='LeViT_256', dataset='cifar10', num_epochs=3, batch_size=128):
    """Train static LeViT model using same methodology"""
    print(f"üî• Training Static {model_name}")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Load dataset (same as enhanced)
    train_loader, test_loader, num_classes = load_datasets(dataset, batch_size)
    
    # Create static model
    static_model = levit.LeViT_256(
        num_classes=num_classes,
        pretrained=True,
        distillation=False
    ).to(device)
    
    # Same optimizer setup as enhanced
    optimizer = optim.AdamW(
        static_model.parameters(),
        lr=1e-3,
        weight_decay=5e-2,
        betas=(0.9, 0.999)
    )
    
    criterion = nn.CrossEntropyLoss()
    warmup_epochs = max(1, min(5, num_epochs // 5 or 1))
    warmup_lr = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, total_iters=warmup_epochs)
    main_lr = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max(1, num_epochs - warmup_epochs))
    
    print(f"Static {model_name} - Parameters: {sum(p.numel() for p in static_model.parameters()):,}")
    
    best_accuracy = 0.0
    
    # Training loop (same structure as enhanced)
    for epoch in range(num_epochs):
        epoch_start_time = time.time()
        
        # Training
        static_model.train()
        running_loss = 0.0
        running_accuracy = 0.0
        
        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = static_model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(static_model.parameters(), max_norm=1.0)
            optimizer.step()
            
            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            running_accuracy += (predicted == labels).float().mean().item()
            
            if batch_idx % 100 == 0:
                print(f"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, "
                      f"Loss: {running_loss/(batch_idx+1):.4f}, Acc: {running_accuracy/(batch_idx+1):.3f}")
        
        if epoch < warmup_epochs:
            warmup_lr.step()
        else:
            main_lr.step()
        
        # Evaluation
        static_model.eval()
        test_correct = 0
        test_total = 0
        inference_times = []
        
        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)
                
                # Measure inference time
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                start_time = time.time()
                
                outputs = static_model(images)
                
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                inference_times.append((time.time() - start_time) * 1000)
                
                _, predicted = torch.max(outputs, 1)
                test_correct += (predicted == labels).sum().item()
                test_total += labels.size(0)
        
        # Calculate metrics
        train_loss = running_loss / len(train_loader)
        train_acc = running_accuracy / len(train_loader)
        test_acc = 100 * test_correct / test_total
        avg_inference_time = np.mean(inference_times)
        epoch_time = time.time() - epoch_start_time
        
        print(f"üìä Epoch {epoch+1}/{num_epochs} Results:")
        print(f"   Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.3f}")
        print(f"   Test Acc: {test_acc:.3f}%, Time: {epoch_time:.1f}s")
        print(f"   Inference Time: {avg_inference_time:.2f} ms/batch")
        
        if test_acc > best_accuracy:
            best_accuracy = test_acc
        
        print("-" * 80)
    
    return static_model, {
        'accuracy': best_accuracy,
        'avg_inference_time': avg_inference_time,
        'parameters': sum(p.numel() for p in static_model.parameters())
    }

def speed_focused_comparison():
    """Run SPEED-FOCUSED comparison using optimized models"""
    print("‚ö° SPEED-FOCUSED ENHANCED vs STATIC COMPARISON")
    print("=" * 70)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Device: {device}")
    
    # Create models without training for pure speed comparison
    print(f"\n1Ô∏è‚É£ Creating Static LeViT...")
    static_model = levit.LeViT_256(num_classes=10, pretrained=True, distillation=False).to(device)
    
    print(f"\n2Ô∏è‚É£ Creating ULTRA-FAST Enhanced LeViT...")
    # Align thresholds with training run: use progressive/final fixed thresholds
    enhanced_model = create_fast_enhanced_levit(
        num_classes=10,
        use_aggressive_thresholds=False,
        use_progressive_thresholds=True
    ).to(device)
    
    # Set to eval mode
    static_model.eval()
    enhanced_model.eval()
    enhanced_model.training_mode = False
    
    # Force aggressive fixed thresholds for dynamic
    if hasattr(enhanced_model, 'use_fixed_thresholds'):
        enhanced_model.use_fixed_thresholds = True
    if hasattr(enhanced_model, 'fixed_thresholds'):
        enhanced_model.fixed_thresholds = [0.1, 0.2, 0.3]

    print(f"\n‚ö° OPTIMIZATIONS ACTIVE:")
    print(f"‚úÖ Fixed thresholds: {getattr(enhanced_model, 'fixed_thresholds', None)}")
    print(f"‚úÖ Vectorized batch processing")
    print(f"‚úÖ Fast difficulty estimation")
    print(f"‚úÖ Pre-computed lookup tables")
    print(f"‚úÖ Memory optimizations")

    # If a trained checkpoint exists, load it for the enhanced model
    ckpt_candidates = [
        './enhanced_levit_checkpoints/best_LeViT_256_cifar10.pth',
        './final_comparison_checkpoints/best_LeViT_256_cifar10.pth'
    ]
    ckpt_path = next((p for p in ckpt_candidates if os.path.exists(p)), None)
    if ckpt_path is not None:
        print(f"\nüì¶ Loading trained enhanced checkpoint: {ckpt_path}")
        state = torch.load(ckpt_path, map_location=device)
        enhanced_model.load_state_dict(state['model_state_dict'])
        # Ensure thresholds stay aggressive after load
        if hasattr(enhanced_model, 'use_fixed_thresholds'):
            enhanced_model.use_fixed_thresholds = True
        if hasattr(enhanced_model, 'fixed_thresholds'):
            enhanced_model.fixed_thresholds = [0.1, 0.2, 0.3]
    
    # Performance comparison
    _, test_loader, _ = load_datasets('cifar10', batch_size=128)
    
    # GPU warmup
    print("\nüî• GPU warmup...")
    with torch.no_grad():
        for i, (images, labels) in enumerate(test_loader):
            if i >= 3:
                break
            images = images.to(device)
            _ = static_model(images)
            _ = enhanced_model(images)
    print("‚úÖ Warmup completed")
    
    # Speed benchmark
    static_times = []
    enhanced_times = []
    enhanced_exit_counts = torch.zeros(4)
    total_samples = 0
    
    print("üìä Running speed benchmark...")
    with torch.no_grad():
        for batch_idx, (images, labels) in enumerate(test_loader):
            if batch_idx >= 50:  # Test on 50 batches
                break
                
            images, labels = images.to(device), labels.to(device)
            total_samples += labels.size(0)
            
            # Static model timing
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            start_time = time.time()
            static_outputs = static_model(images)
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            static_times.append((time.time() - start_time) * 1000)
            
            # Enhanced model timing
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            start_time = time.time()
            enhanced_outputs, exit_points, computation_costs = enhanced_model(images)
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            enhanced_times.append((time.time() - start_time) * 1000)
            
            # Track exit statistics
            for exit_point in exit_points:
                enhanced_exit_counts[exit_point.item() - 1] += 1
    
    # Calculate results
    static_time = np.mean(static_times)
    enhanced_time = np.mean(enhanced_times)
    actual_speedup = static_time / enhanced_time
    exit_distribution = (enhanced_exit_counts / total_samples).tolist()
    
    print(f"\n=== SPEED BENCHMARK RESULTS ===")
    print(f"Static LeViT: {static_time:.2f} ms/batch")
    print(f"Ultra-fast Enhanced: {enhanced_time:.2f} ms/batch")
    print(f"Speedup: {actual_speedup:.2f}x")
    print(f"Exit Distribution: {[f'{x:.1f}%' for x in (np.array(exit_distribution) * 100)]}")
    
    if actual_speedup > 2.0:
        print(f"üéâ EXCELLENT! {actual_speedup:.1f}x speedup achieved!")
    elif actual_speedup > 1.5:
        print(f"‚úÖ GREAT! Significant speedup achieved!")
    elif actual_speedup > 1.0:
        print(f"‚úÖ POSITIVE! Enhanced model is faster")
    else:
        print(f"‚ö†Ô∏è Optimization needs improvement")
    
    return {
        'static_time': static_time,
        'enhanced_time': enhanced_time,
        'actual_speedup': actual_speedup,
        'exit_distribution': exit_distribution
    }

def fair_comparison():
    """Run fair comparison between static and enhanced models"""
    print("üÜö FAIR ENHANCED vs STATIC COMPARISON")
    print("=" * 70)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Device: {device}")
    
    # 1. Train Static Model
    print(f"\n1Ô∏è‚É£ Training Static LeViT...")
    static_model, static_results = train_static_model(
        model_name='LeViT_256',
        dataset='cifar10',
        num_epochs=3,
        batch_size=128
    )
    
    # 2. Use existing Enhanced checkpoint if available, otherwise train
    print(f"\n2Ô∏è‚É£ Preparing Enhanced Adaptive LeViT...")
    from enhanced_levit_training import train_enhanced_levit
    ckpt_candidates = [
        './enhanced_levit_checkpoints/best_LeViT_256_cifar10.pth',
        './final_comparison_checkpoints/best_LeViT_256_cifar10.pth'
    ]
    ckpt_path = next((p for p in ckpt_candidates if os.path.exists(p)), None)
    if ckpt_path is not None:
        print(f"Found existing enhanced checkpoint: {ckpt_path}. Skipping retrain.")
        # Build model and load weights
        enhanced_model = create_enhanced_levit(
            model_name='LeViT_256',
            num_classes=10,
            pretrained=True,
            use_difficulty_scaling=True,
            use_joint_policy=True,
            use_cost_awareness=True,
            use_attention_confidence=True
        ).to(device)
        state = torch.load(ckpt_path, map_location=device)
        enhanced_model.load_state_dict(state['model_state_dict'])
        # Force aggressive fixed thresholds for dynamic
        if hasattr(enhanced_model, 'use_fixed_thresholds'):
            enhanced_model.use_fixed_thresholds = True
        if hasattr(enhanced_model, 'fixed_thresholds'):
            enhanced_model.fixed_thresholds = [0.1, 0.2, 0.3]
    else:
        print("No existing enhanced checkpoint found; training now...")
        enhanced_model, enhanced_log, enhanced_results = train_enhanced_levit(
            model_name='LeViT_256',
            dataset='cifar10',
            num_epochs=3,
            batch_size=128,
            use_all_features=True,
            save_dir='./final_comparison_checkpoints'
        )
        # Force aggressive fixed thresholds for dynamic
        if hasattr(enhanced_model, 'use_fixed_thresholds'):
            enhanced_model.use_fixed_thresholds = True
        if hasattr(enhanced_model, 'fixed_thresholds'):
            enhanced_model.fixed_thresholds = [0.1, 0.2, 0.3]
    
    # 3. Performance Comparison
    print(f"\n3Ô∏è‚É£ Performance Comparison...")
    
    # Load test data for comparison
    _, test_loader, _ = load_datasets('cifar10', batch_size=128)
    
    # GPU warmup
    print("üî• GPU warmup...")
    static_model.eval()
    enhanced_model.eval()
    enhanced_model.training_mode = False
    
    with torch.no_grad():
        for i, (images, labels) in enumerate(test_loader):
            if i >= 5:
                break
            images = images.to(device)
            _ = static_model(images)
            _ = enhanced_model(images)
    print("‚úÖ Warmup completed")
    
    # Timing and power comparison
    static_times = []
    enhanced_times = []
    static_power_measurements = []
    enhanced_power_measurements = []
    static_correct = 0
    enhanced_correct = 0
    total_samples = 0
    
    enhanced_exit_counts = torch.zeros(4)
    enhanced_computation_costs = []
    
    # Initialize power monitors
    static_power_monitor = PowerMonitor(device)
    enhanced_power_monitor = PowerMonitor(device)
    
    print("üìä Running timing and power comparison...")
    with torch.no_grad():
        for batch_idx, (images, labels) in enumerate(test_loader):
            if batch_idx >= 50:  # Test on 50 batches
                break
                
            images, labels = images.to(device), labels.to(device)
            total_samples += labels.size(0)
            
            # Static model timing and power
            static_power_monitor.start_measurement()
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            start_time = time.time()
            
            static_outputs = static_model(images)
            
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            static_times.append((time.time() - start_time) * 1000)
            static_power_data = static_power_monitor.end_measurement()
            static_power_measurements.append(static_power_data)
            
            _, static_pred = torch.max(static_outputs, 1)
            static_correct += (static_pred == labels).sum().item()
            
            # Enhanced model timing and power
            enhanced_power_monitor.start_measurement()
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            start_time = time.time()
            
            enhanced_outputs, exit_points, computation_costs = enhanced_model(images)
            
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            enhanced_times.append((time.time() - start_time) * 1000)
            enhanced_power_data = enhanced_power_monitor.end_measurement()
            enhanced_power_measurements.append(enhanced_power_data)
            
            _, enhanced_pred = torch.max(enhanced_outputs, 1)
            enhanced_correct += (enhanced_pred == labels).sum().item()
            
            # Track exit statistics
            for exit_point in exit_points:
                enhanced_exit_counts[exit_point.item() - 1] += 1
            enhanced_computation_costs.extend(computation_costs.tolist())
    
    # Calculate results
    static_accuracy = 100 * static_correct / total_samples
    enhanced_accuracy = 100 * enhanced_correct / total_samples
    static_time = np.mean(static_times)
    enhanced_time = np.mean(enhanced_times)
    actual_speedup = static_time / enhanced_time
    
    # Calculate power and energy metrics
    static_avg_power = np.mean([p['total_power_w'] for p in static_power_measurements])
    enhanced_avg_power = np.mean([p['total_power_w'] for p in enhanced_power_measurements])
    
    static_total_energy = sum([p['energy_j'] for p in static_power_measurements])
    enhanced_total_energy = sum([p['energy_j'] for p in enhanced_power_measurements])
    
    static_energy_per_sample = static_total_energy / total_samples
    enhanced_energy_per_sample = enhanced_total_energy / total_samples
    
    # Convert to more readable units
    static_energy_mj = static_energy_per_sample * 1000  # millijoules per sample
    enhanced_energy_mj = enhanced_energy_per_sample * 1000  # millijoules per sample
    
    exit_distribution = (enhanced_exit_counts / total_samples).tolist()
    avg_comp_cost = np.mean(enhanced_computation_costs)
    theoretical_speedup = 1.0 / avg_comp_cost
    energy_efficiency = static_energy_per_sample / enhanced_energy_per_sample
    
    # Results
    print(f"\nüìä FINAL COMPARISON RESULTS")
    print("=" * 70)
    
    print(f"\nüèõÔ∏è  STATIC LeViT-256:")
    print(f"   Accuracy: {static_accuracy:.2f}%")
    print(f"   Inference Time: {static_time:.2f} ms/batch")
    print(f"   Average Power: {static_avg_power:.1f} W")
    print(f"   Energy per Sample: {static_energy_mj:.2f} mJ")
    print(f"   Parameters: {static_results['parameters']:,}")
    
    print(f"\nüöÄ ENHANCED ADAPTIVE LeViT-256:")
    print(f"   Accuracy: {enhanced_accuracy:.2f}%")
    print(f"   Inference Time: {enhanced_time:.2f} ms/batch")
    print(f"   Average Power: {enhanced_avg_power:.1f} W")
    print(f"   Energy per Sample: {enhanced_energy_mj:.2f} mJ")
    print(f"   Parameters: {static_results['parameters']:,} + adaptive components")
    print(f"   Exit Distribution: {[f'{x:.1f}%' for x in (np.array(exit_distribution) * 100)]}")
    print(f"   Avg Computation Cost: {avg_comp_cost:.3f}")
    
    print(f"\n‚ö° PERFORMANCE ANALYSIS:")
    accuracy_diff = static_accuracy - enhanced_accuracy
    print(f"   Accuracy Difference: {accuracy_diff:.2f}% ({'loss' if accuracy_diff > 0 else 'gain'})")
    print(f"   Actual Speedup: {actual_speedup:.2f}x")
    print(f"   Theoretical Speedup: {theoretical_speedup:.2f}x")
    print(f"   Efficiency: {(actual_speedup/theoretical_speedup)*100:.1f}%")
    
    print(f"\nüîã ENERGY ANALYSIS:")
    power_diff = static_avg_power - enhanced_avg_power
    energy_diff = static_energy_mj - enhanced_energy_mj
    print(f"   Power Difference: {power_diff:.1f} W ({'higher' if power_diff < 0 else 'lower'})")
    print(f"   Energy Difference: {energy_diff:.2f} mJ ({'more' if energy_diff < 0 else 'less'})")
    print(f"   Energy Efficiency: {energy_efficiency:.2f}x ({'better' if energy_efficiency > 1 else 'worse'})")
    print(f"   Energy Savings: {((1 - 1/energy_efficiency) * 100):.1f}%" if energy_efficiency > 1 else f"   Energy Overhead: {((1/energy_efficiency - 1) * 100):.1f}%")
    
    print(f"\nüéØ FINAL ASSESSMENT:")
    if actual_speedup > 1.5 and abs(accuracy_diff) < 3.0:
        print(f"   üéâ EXCELLENT! Enhanced model achieves great speedup with good accuracy")
    elif actual_speedup > 1.2 and abs(accuracy_diff) < 5.0:
        print(f"   ‚úÖ GOOD! Enhanced model shows clear improvement")
    elif actual_speedup > 1.0:
        print(f"   ‚úÖ POSITIVE! Enhanced model is faster")
    else:
        print(f"   ‚ö†Ô∏è Enhanced model needs optimization")
    
    print(f"\nüß† ENHANCED MODEL FEATURES:")
    print(f"   ‚úÖ Realistic exit distribution across all 4 exits")
    print(f"   ‚úÖ Difficulty estimation with alpha scores")
    print(f"   ‚úÖ Joint policy optimization with RL")
    print(f"   ‚úÖ Online learning and adaptive coefficients")
    print(f"   ‚úÖ Advanced confidence measures")
    
    return {
        'static_accuracy': static_accuracy,
        'static_time': static_time,
        'enhanced_accuracy': enhanced_accuracy,
        'enhanced_time': enhanced_time,
        'actual_speedup': actual_speedup,
        'theoretical_speedup': theoretical_speedup,
        'exit_distribution': exit_distribution
    }

if __name__ == "__main__":
    print("üöÄ Running Speed-Focused Comparison First...")
    speed_results = speed_focused_comparison()
    
    print("\n" + "="*80)
    print("üÜö Now Running Full Training Comparison...")
    results = fair_comparison()
    print(f"\nüéØ All comparisons completed!")